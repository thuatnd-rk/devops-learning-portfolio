# Machine Learning Foundations for DevOps Engineers

## üìã Overview
T√†i li·ªáu n√†y t·ªïng h·ª£p ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ Machine Learning t·ª´ video [ML Foundations](https://www.youtube.com/watch?v=BUTjcAjfMgY) v√† b·ªï sung c√°c tools/ki·∫øn th·ª©c DevOps c·∫ßn bi·∫øt ƒë·ªÉ tham gia v√†o d·ª± √°n ML/AI.

## üß† Tr√≠ tu·ªá v√† M√¥ h√¨nh Th·∫ø gi·ªõi

### 1.1 Kh√°i ni·ªám c∆° b·∫£n
- **Tr√≠ tu·ªá** ƒë√≤i h·ªèi s·ª± hi·ªÉu bi·∫øt v·ªÅ c√°ch th·∫ø gi·ªõi v·∫≠n h√†nh
- **M√¥ h√¨nh th·∫ø gi·ªõi** gi√∫p n√©n th·ª±c t·∫ø ph·ª©c t·∫°p th√†nh d·∫°ng c√≥ th·ªÉ h√¨nh dung ƒë∆∞·ª£c
- **M√¥ h√¨nh** cho ph√©p ƒë∆∞a ra d·ª± ƒëo√°n (v√≠ d·ª•: m√¢y ƒëen ‚Üí tr·ªùi s·∫Øp m∆∞a)

### 1.2 DevOps Perspective
```yaml
# Example: Monitoring model performance
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-monitoring-config
data:
  config.yaml: |
    model_metrics:
      - accuracy
      - precision
      - recall
      - f1_score
    infrastructure_metrics:
      - cpu_usage
      - memory_usage
      - gpu_utilization
      - response_time
```

## ü§ñ Machine Learning (ML): Thu·∫≠t ng·ªØ chung

### 2.1 ƒê·ªãnh nghƒ©a
- **ML** = "Gi√∫p m√°y t√≠nh th·ª±c hi·ªán c√°c t√°c v·ª• m√† kh√¥ng c·∫ßn h∆∞·ªõng d·∫´n r√µ r√†ng"
- Kh√°c v·ªõi ph√°t tri·ªÉn ph·∫ßn m·ªÅm truy·ªÅn th·ªëng d·ª±a tr√™n h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc

### 2.2 C√°c giai ƒëo·∫°n ch√≠nh

#### 2.2.1 Hu·∫•n luy·ªán (Training)
```python
# Example: Training pipeline
from sklearn.linear_model import LinearRegression
import pandas as pd

# 1. Thu th·∫≠p d·ªØ li·ªáu
training_data = pd.read_csv('training_data.csv')

# 2. ƒê∆∞a d·ªØ li·ªáu cho thu·∫≠t to√°n h·ªçc
model = LinearRegression()
model.fit(training_data[['feature1', 'feature2']], training_data['target'])

# 3. K·∫øt qu·∫£ l√† m√¥ h√¨nh h·ªçc m√°y
# model now contains learned parameters
```

#### 2.2.2 Suy lu·∫≠n (Inference)
```python
# Example: Inference service
from fastapi import FastAPI
import joblib

app = FastAPI()
model = joblib.load('trained_model.pkl')

@app.post("/predict")
async def predict(data: dict):
    prediction = model.predict([data['features']])
    return {"prediction": prediction[0]}
```

### 2.3 DevOps Tools cho Training Pipeline

#### 2.3.1 MLflow - Model Lifecycle Management
```yaml
# Example: MLflow tracking
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlflow-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mlflow
  template:
    spec:
      containers:
      - name: mlflow
        image: mlflow:latest
        ports:
        - containerPort: 5000
        env:
        - name: MLFLOW_TRACKING_URI
          value: "sqlite:///mlflow.db"
```

#### 2.3.2 Kubeflow - ML Workflow Orchestration
```yaml
# Example: Kubeflow pipeline
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: ml-training-pipeline
spec:
  templates:
  - name: data-preprocessing
    container:
      image: python:3.8
      command: ["python", "preprocess.py"]
  - name: model-training
    container:
      image: tensorflow:latest
      command: ["python", "train.py"]
  - name: model-evaluation
    container:
      image: python:3.8
      command: ["python", "evaluate.py"]
```

### 2.4 Hu·∫•n luy·ªán M√¥ h√¨nh: Kh√°i ni·ªám c·ªët l√µi

#### 2.4.1 M·ª•c ti√™u
- T√¨m c√°c gi√° tr·ªã tham s·ªë t∆∞∆°ng ·ª©ng v·ªõi h√†m m·∫•t m√°t nh·ªè nh·∫•t
- Gi·∫£m thi·ªÉu s·ª± kh√°c bi·ªát gi·ªØa d·ª± ƒëo√°n v√† d·ªØ li·ªáu th·ª±c t·∫ø

#### 2.4.2 H√†m m·∫•t m√°t (Loss Function)
```python
# Example: Loss function monitoring
import prometheus_client
from prometheus_client import Counter, Histogram

# Metrics for monitoring
prediction_errors = Counter('model_prediction_errors_total', 'Total prediction errors')
prediction_latency = Histogram('model_prediction_duration_seconds', 'Prediction latency')

def predict_with_monitoring(features):
    start_time = time.time()
    try:
        prediction = model.predict(features)
        prediction_latency.observe(time.time() - start_time)
        return prediction
    except Exception as e:
        prediction_errors.inc()
        raise e
```

### 2.5 C√°c k·ªπ thu·∫≠t ML truy·ªÅn th·ªëng

#### 2.5.1 H·ªìi quy Logistic
```python
# Example: Logistic regression deployment
from sklearn.linear_model import LogisticRegression
import joblib

# Train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Save model
joblib.dump(model, 'logistic_model.pkl')
```

#### 2.5.2 C√¢y quy·∫øt ƒë·ªãnh
```python
# Example: Decision tree with model versioning
from sklearn.tree import DecisionTreeClassifier
import mlflow

with mlflow.start_run():
    model = DecisionTreeClassifier(max_depth=5)
    model.fit(X_train, y_train)
    
    # Log model
    mlflow.sklearn.log_model(model, "decision_tree")
    
    # Log parameters
    mlflow.log_param("max_depth", 5)
    mlflow.log_metric("accuracy", model.score(X_test, y_test))
```

### 2.6 H·∫°n ch·∫ø: K·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng (Feature Engineering)
- ƒê√≤i h·ªèi l∆∞·ª£ng l·ªõn th·ªùi gian v√† ki·∫øn th·ª©c chuy√™n m√¥n
- DevOps c·∫ßn hi·ªÉu v·ªÅ data pipeline v√† feature store

```yaml
# Example: Feature store with Feast
apiVersion: apps/v1
kind: Deployment
metadata:
  name: feast-feature-store
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: feast-server
        image: feast:latest
        ports:
        - containerPort: 6566
        env:
        - name: FEAST_CORE_URL
          value: "feast-core:6565"
```

## üß† Deep Learning (DL): H·ªçc t·ª± ƒë·ªông c√°c ƒë·∫∑c tr∆∞ng

### 3.1 ƒê·ªãnh nghƒ©a
- **DL** = "Lo·∫°i h·ªçc m√°y c·ª• th·ªÉ li√™n quan ƒë·∫øn vi·ªác hu·∫•n luy·ªán m·∫°ng th·∫ßn kinh"
- C√≥ th·ªÉ t·ª± h·ªçc c√°c ƒë·∫∑c tr∆∞ng t·ªëi ∆∞u cho m·ªôt nhi·ªám v·ª• c·ª• th·ªÉ

### 3.2 M·∫°ng th·∫ßn kinh (Neural Networks)

#### 3.2.1 Nguy√™n l√Ω ho·∫°t ƒë·ªông
```python
# Example: Simple neural network
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

#### 3.2.2 DevOps cho Neural Networks
```yaml
# Example: GPU-enabled training deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: neural-network-training
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: training
        image: tensorflow:latest
        resources:
          requests:
            nvidia.com/gpu: 1
            memory: "8Gi"
            cpu: "4"
          limits:
            nvidia.com/gpu: 1
            memory: "16Gi"
            cpu: "8"
        volumeMounts:
        - name: training-data
          mountPath: /data
        - name: model-storage
          mountPath: /models
```

### 3.3 C√°c lo·∫°i n∆°-ron v√† h√†m k√≠ch ho·∫°t

#### 3.3.1 H√†m k√≠ch ho·∫°t ph·ªï bi·∫øn
- **ReLU**: `f(x) = max(0, x)`
- **Sigmoid**: `f(x) = 1/(1 + e^(-x))`
- **Tanh**: `f(x) = (e^x - e^(-x))/(e^x + e^(-x))`
- **Softmax**: Chuy·ªÉn ƒë·ªïi ƒë·∫ßu v√†o th√†nh ph√¢n ph·ªëi x√°c su·∫•t

#### 3.3.2 Monitoring Activation Functions
```python
# Example: Monitoring activation function performance
import tensorflow as tf
from tensorflow.keras.callbacks import Callback

class ActivationMonitor(Callback):
    def on_epoch_end(self, epoch, logs=None):
        # Monitor activation patterns
        layer_outputs = self.model.predict(self.validation_data[0])
        tf.summary.scalar('activation_stats', tf.reduce_mean(layer_outputs))
```

### 3.4 Ki·∫øn tr√∫c m·∫°ng

#### 3.4.1 M·∫°ng th·∫ßn kinh truy·ªÅn th·∫≥ng (Feed-forward)
```python
# Example: Feed-forward network deployment
apiVersion: v1
kind: Service
metadata:
  name: feed-forward-model
spec:
  selector:
    app: feed-forward-model
  ports:
  - port: 8080
    targetPort: 8080
  type: LoadBalancer
```

#### 3.4.2 M·∫°ng th·∫ßn kinh t√≠ch ch·∫≠p (CNN)
```python
# Example: CNN for image processing
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
```

#### 3.4.3 Transformer
- C√°ch m·∫°ng h√≥a x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n
- Ki·∫øn tr√∫c ƒë·∫±ng sau c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn

### 3.5 Hu·∫•n luy·ªán: Gradient Descent

#### 3.5.1 Nguy√™n l√Ω
- H√†m m·∫•t m√°t ph·ª©c t·∫°p h∆°n m√¥ h√¨nh tuy·∫øn t√≠nh
- C√≥ "ƒë·ªãa h√¨nh l·ªüm ch·ªüm" c·ªßa c√°c ƒë·ªânh v√† thung l≈©ng
- Gradient cho bi·∫øt h∆∞·ªõng d·ªëc nh·∫•t

#### 3.5.2 C√°c bi·∫øn th·ªÉ
```python
# Example: Different optimizers
optimizers = {
    'sgd': tf.keras.optimizers.SGD(learning_rate=0.01),
    'adam': tf.keras.optimizers.Adam(learning_rate=0.001),
    'rmsprop': tf.keras.optimizers.RMSprop(learning_rate=0.001)
}
```

#### 3.5.3 DevOps cho Gradient Descent
```yaml
# Example: Distributed training with Horovod
apiVersion: apps/v1
kind: Job
metadata:
  name: distributed-training
spec:
  parallelism: 4
  template:
    spec:
      containers:
      - name: training
        image: horovod/horovod:latest
        command: ["horovodrun", "-np", "4", "python", "train.py"]
        env:
        - name: HOROVOD_RING
          value: "nccl"
```

### 3.6 Si√™u tham s·ªë (Hyperparameters)

#### 3.6.1 ƒê·ªãnh nghƒ©a
- C√°c gi√° tr·ªã h∆∞·ªõng d·∫´n qu√° tr√¨nh hu·∫•n luy·ªán
- Kh√¥ng ph·∫£i tham s·ªë m√¥ h√¨nh ƒë∆∞·ª£c h·ªçc t·ª´ d·ªØ li·ªáu
- ƒê∆∞·ª£c ƒë·∫∑t th·ªß c√¥ng ho·∫∑c ƒëi·ªÅu ch·ªânh th√¥ng qua t·ªëi ∆∞u h√≥a

#### 3.6.2 C√°c si√™u tham s·ªë ph·ªï bi·∫øn
```python
# Example: Hyperparameter configuration
hyperparameters = {
    'epochs': 100,
    'learning_rate': 0.001,
    'batch_size': 32,
    'dropout_rate': 0.2,
    'hidden_layers': [128, 64, 32]
}
```

#### 3.6.3 DevOps cho Hyperparameter Tuning
```yaml
# Example: Hyperparameter tuning with Katib
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  name: hyperparameter-tuning
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
  - name: learning_rate
    parameterType: double
    feasibleSpace:
      min: "0.01"
      max: "0.1"
  - name: batch_size
    parameterType: int
    feasibleSpace:
      min: "16"
      max: "128"
```

## üéØ Reinforcement Learning (RL): H·ªçc qua th·ª≠ v√† sai

### 4.1 ƒê·ªãnh nghƒ©a
- M√°y t√≠nh c√≥ th·ªÉ h·ªçc th√¥ng qua th·ª≠ v√† sai
- T∆∞∆°ng t√°c tr·ª±c ti·∫øp v·ªõi m√¥i tr∆∞·ªùng
- Kh√¥ng b·ªã r√†ng bu·ªôc b·ªüi nh√£n c·ªßa con ng∆∞·ªùi

### 4.2 C√°ch ho·∫°t ƒë·ªông

#### 4.2.1 V√≤ng l·∫∑p ph·∫£n h·ªìi
```python
# Example: RL environment setup
import gym
import numpy as np

env = gym.make('CartPole-v1')
state = env.reset()

for step in range(1000):
    action = model.predict(state)  # Model decides action
    next_state, reward, done, info = env.step(action)
    
    # Update model based on reward
    model.update(state, action, reward, next_state)
    
    if done:
        break
    state = next_state
```

#### 4.2.2 DevOps cho RL
```yaml
# Example: RL training environment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rl-training-environment
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: rl-agent
        image: rl-training:latest
        env:
        - name: ENVIRONMENT_NAME
          value: "CartPole-v1"
        - name: MODEL_PATH
          value: "/models/rl_model"
        volumeMounts:
        - name: model-storage
          mountPath: /models
```

### 4.3 M·ª•c ti√™u: T·ªëi ƒëa h√≥a h√†m ph·∫ßn th∆∞·ªüng

#### 4.3.1 H√†m ph·∫ßn th∆∞·ªüng
```python
# Example: Reward function monitoring
class RewardMonitor:
    def __init__(self):
        self.total_reward = 0
        self.episode_count = 0
    
    def log_reward(self, reward):
        self.total_reward += reward
        tf.summary.scalar('episode_reward', reward)
    
    def log_episode(self):
        self.episode_count += 1
        avg_reward = self.total_reward / self.episode_count
        tf.summary.scalar('average_reward', avg_reward)
```

### 4.4 C√°c thu·∫≠t to√°n RL hi·ªán ƒë·∫°i

#### 4.4.1 PPO (Proximal Policy Optimization)
- ƒê∆∞·ª£c s·ª≠ d·ª•ng trong RLHF (Reinforcement Learning from Human Feedback)
- OpenAI s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o ChatGPT

#### 4.4.2 GRPO (Group Relative Policy Optimization)
- DeepSeek s·ª≠ d·ª•ng trong DeepSeek R1
- K·∫øt h·ª£p PPO v·ªõi h√¨nh ph·∫°t KL divergence

## üìä D·ªØ li·ªáu: Th√†nh ph·∫ßn quan tr·ªçng nh·∫•t

### 5.1 Nguy√™n t·∫Øc "Garbage in, garbage out"
- N·∫øu c√≥ d·ªØ li·ªáu x·∫•u ‚Üí m√¥ h√¨nh x·∫•u
- B·∫•t k·ªÉ thu·∫≠t to√°n tinh vi ƒë·∫øn m·ª©c n√†o

### 5.2 Hai thu·ªôc t√≠nh c·ªßa d·ªØ li·ªáu t·ªët

#### 5.2.1 S·ªë l∆∞·ª£ng
- Nhi·ªÅu d·ªØ li·ªáu t·ªët h∆°n √≠t d·ªØ li·ªáu
- Thi·∫øu d·ªØ li·ªáu ‚Üí overfitting

#### 5.2.2 Ch·∫•t l∆∞·ª£ng
- **ƒê·ªô ch√≠nh x√°c**: S·ª± ƒë√∫ng ƒë·∫Øn c·ªßa d·ªØ li·ªáu
- **T√≠nh ƒëa d·∫°ng**: T√≠nh ƒë·∫°i di·ªán c·ªßa d·ªØ li·ªáu

### 5.3 DevOps cho Data Pipeline

#### 5.3.1 Data Versioning v·ªõi DVC
```yaml
# Example: DVC configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: dvc-config
data:
  .dvc/config: |
    [core]
      remote = myremote
    ['remote "myremote"']
      url = s3://my-bucket/dvc
      storagepath = /data
```

#### 5.3.2 Data Pipeline v·ªõi Apache Airflow
```python
# Example: Airflow DAG for data processing
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime

dag = DAG('data_pipeline', start_date=datetime(2024, 1, 1))

def extract_data():
    # Extract data from sources
    pass

def transform_data():
    # Transform and clean data
    pass

def load_data():
    # Load data to storage
    pass

extract_task = PythonOperator(task_id='extract', python_callable=extract_data, dag=dag)
transform_task = PythonOperator(task_id='transform', python_callable=transform_data, dag=dag)
load_task = PythonOperator(task_id='load', python_callable=load_data, dag=dag)

extract_task >> transform_task >> load_task
```

#### 5.3.3 Data Quality Monitoring
```python
# Example: Data quality checks
import great_expectations as ge

def validate_data_quality():
    context = ge.get_context()
    
    # Validate data schema
    validator = context.get_validator(
        batch_request=batch_request,
        expectation_suite=expectation_suite_name
    )
    
    # Check for missing values
    validator.expect_column_values_to_not_be_null("target")
    
    # Check data types
    validator.expect_column_values_to_be_of_type("age", "int")
    
    # Check value ranges
    validator.expect_column_values_to_be_between("age", 0, 120)
    
    return validator.validate()
```

## üõ†Ô∏è DevOps Tools & Best Practices cho ML/AI

### 6.1 Model Serving

#### 6.1.1 TensorFlow Serving
```yaml
# Example: TensorFlow Serving deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-serving
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: serving
        image: tensorflow/serving:latest
        ports:
        - containerPort: 8500
        - containerPort: 8501
        env:
        - name: MODEL_NAME
          value: "my_model"
        - name: MODEL_BASE_PATH
          value: "/models"
        volumeMounts:
        - name: model-storage
          mountPath: /models
```

#### 6.1.2 Seldon Core
```yaml
# Example: Seldon deployment
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: ml-model
spec:
  name: ml-model
  predictors:
  - name: default
    replicas: 3
    graph:
      name: classifier
      type: MODEL
      modelUri: s3://my-bucket/model
      serviceAccountName: seldon-init-container
```

### 6.2 Model Monitoring

#### 6.2.1 Prometheus Metrics
```python
# Example: Custom metrics for ML models
from prometheus_client import Counter, Histogram, Gauge

# Model performance metrics
prediction_counter = Counter('model_predictions_total', 'Total predictions made')
prediction_latency = Histogram('model_prediction_duration_seconds', 'Prediction latency')
model_accuracy = Gauge('model_accuracy', 'Model accuracy')

def predict_with_metrics(features):
    start_time = time.time()
    
    try:
        prediction = model.predict(features)
        prediction_counter.inc()
        prediction_latency.observe(time.time() - start_time)
        return prediction
    except Exception as e:
        # Log error metrics
        raise e
```

#### 6.2.2 Model Drift Detection
```python
# Example: Drift detection
import numpy as np
from scipy import stats

def detect_drift(reference_data, current_data):
    # Statistical drift detection
    reference_mean = np.mean(reference_data)
    current_mean = np.mean(current_data)
    
    # T-test for drift
    t_stat, p_value = stats.ttest_ind(reference_data, current_data)
    
    if p_value < 0.05:
        return True, f"Drift detected: p-value={p_value}"
    
    return False, "No significant drift detected"
```

### 6.3 A/B Testing cho Models

#### 6.3.1 Traffic Splitting
```yaml
# Example: A/B testing configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: ab-testing-config
data:
  config.yaml: |
    experiments:
      - name: model-comparison
        traffic_split:
          model_a: 50
          model_b: 50
        metrics:
          - accuracy
          - latency
          - user_satisfaction
```

#### 6.3.2 Canary Deployment
```yaml
# Example: Canary deployment for ML models
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-canary
spec:
  replicas: 1  # Small percentage
  template:
    spec:
      containers:
      - name: model-server
        image: model:canary
        env:
        - name: MODEL_VERSION
          value: "v2.0.0-canary"
```

### 6.4 Security cho ML Models

#### 6.4.1 Model Encryption
```python
# Example: Model encryption
import cryptography
from cryptography.fernet import Fernet

def encrypt_model(model_path, key):
    with open(model_path, 'rb') as f:
        model_data = f.read()
    
    f = Fernet(key)
    encrypted_data = f.encrypt(model_data)
    
    with open(f"{model_path}.encrypted", 'wb') as f:
        f.write(encrypted_data)
```

#### 6.4.2 Input Validation
```python
# Example: Input validation for ML models
from pydantic import BaseModel, validator
import numpy as np

class ModelInput(BaseModel):
    features: list
    
    @validator('features')
    def validate_features(cls, v):
        if len(v) != 784:  # Expected feature count
            raise ValueError('Feature count must be 784')
        
        if not all(isinstance(x, (int, float)) for x in v):
            raise ValueError('All features must be numeric')
        
        return v
```

### 6.5 CI/CD cho ML

#### 6.5.1 GitHub Actions Workflow
```yaml
# Example: ML CI/CD pipeline
name: ML Model CI/CD
on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Run tests
      run: |
        python -m pytest tests/
    
    - name: Validate model performance
      run: |
        python scripts/validate_model.py
    
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to staging
      run: |
        kubectl apply -f k8s/staging/
    
    - name: Run smoke tests
      run: |
        python scripts/smoke_test.py
    
    - name: Deploy to production
      run: |
        kubectl apply -f k8s/production/
```

## üìö T·ªïng k·∫øt

### 6.1 C√°c √Ω ch√≠nh
1. **Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ** ƒë√≤i h·ªèi m√¥ h√¨nh th·∫ø gi·ªõi ch√≠nh x√°c
2. **ML** cung c·∫•p c√°ch ƒëi·ªÅu ch·ªânh m√¥ h√¨nh cho th·ª±c t·∫ø
3. **DL** s·ª≠ d·ª•ng m·∫°ng th·∫ßn kinh ƒë·ªÉ h·ªçc ƒë·∫∑c tr∆∞ng
4. **RL** cho ph√©p h·ªçc qua t∆∞∆°ng t√°c v·ªõi m√¥i tr∆∞·ªùng
5. **D·ªØ li·ªáu** l√† th√†nh ph·∫ßn quan tr·ªçng nh·∫•t

### 6.2 DevOps Checklist cho ML/AI Projects
- [ ] **Model Versioning**: MLflow, DVC
- [ ] **Model Serving**: TensorFlow Serving, Seldon Core
- [ ] **Monitoring**: Prometheus, Grafana
- [ ] **A/B Testing**: Traffic splitting, canary deployment
- [ ] **Security**: Model encryption, input validation
- [ ] **CI/CD**: Automated testing, deployment
- [ ] **Data Pipeline**: Airflow, DVC
- [ ] **Infrastructure**: Kubernetes, GPU support
- [ ] **Observability**: Logging, metrics, tracing

### 6.3 Key Takeaway
> "M·∫∑c d√π c√≥ r·∫•t nhi·ªÅu to√°n h·ªçc v√† c√°c thu·∫≠t to√°n ph·ª©c t·∫°p trong h·ªçc m√°y, vi·ªác hu·∫•n luy·ªán c√°c m√¥ h√¨nh t·ªët ph·ª• thu·ªôc v√†o vi·ªác c√≥ d·ªØ li·ªáu t·ªët."

---

*Source: [ML Foundations Video](https://www.youtube.com/watch?v=BUTjcAjfMgY)*
*Last updated: January 2024*
*For DevOps engineers working with ML/AI systems*
